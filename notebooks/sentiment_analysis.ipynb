{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsSt1ONMz-8j"
      },
      "source": [
        "# Sentiment analysis - fine-tuning BERT\n",
        "\n",
        "In this notebook we'll take a look at the process needed to fine-tune a pretrained BERT model to detect the sentiment of a piece of text. Our goal will be to classify the polarity of [IMDB](https://www.imdb.com/) movie reviews, we'll be working with this [dataset](https://huggingface.co/datasets/imdb). The techniques we'll discuss also apply to a more general text classification.\n",
        "\n",
        "\n",
        "<div>\n",
        "<img src=\"https://raw.githubusercontent.com/valira-ai/NLP-tutorial-DSC22/main/figures/classification.png\" width=\"700\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhEUupc90qxi"
      },
      "source": [
        "First things first, let's make sure we have a GPU instance in this Colab session:\n",
        "\n",
        "* `Edit -> Notebook settings -> Hardware accelerator` must be set to `GPU`\n",
        "\n",
        "* if needed, reinitiliaze the session by clicking `Connect` in top right corner\n",
        "\n",
        "After the session is initilized, we can check our assigned GPU with the following command:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FD2kH94qeCS"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oj0ukclmqzMo"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers  # Huggingface library for transformer models\n",
        "!pip install datasets  # Huggingface dataset library\n",
        "!pip install --upgrade --no-cache-dir gdown  # downloading from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bIEJUylprFsm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from datasets import DatasetDict, load_dataset\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, EarlyStoppingCallback, Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcrpolmM1LY1"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RYbFDx11Tes"
      },
      "source": [
        "Let's download the dataset of IMDB reviews:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pY_1ZSVSrQF2"
      },
      "outputs": [],
      "source": [
        "raw_dataset = load_dataset(\"imdb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "k5q7OlXKuSHY"
      },
      "outputs": [],
      "source": [
        "split_train = raw_dataset[\"train\"].train_test_split(test_size=0.2)\n",
        "dataset = DatasetDict({\n",
        "    \"train\": split_train[\"train\"],\n",
        "    \"val\": split_train[\"test\"],\n",
        "    \"test\": raw_dataset[\"test\"]\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpG_B0CrrcVG"
      },
      "outputs": [],
      "source": [
        "dataset[\"train\"].features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6sRIWnxskHp"
      },
      "outputs": [],
      "source": [
        "dataset[\"train\"][2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OErmijFP2nOm"
      },
      "source": [
        "Tokenizing our data - preparing model inputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21X0-Ru8ytDd"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "anoifgDJzGqJ"
      },
      "outputs": [],
      "source": [
        "def tokenize(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JrNmTN5zSgw"
      },
      "outputs": [],
      "source": [
        "tok_dataset = dataset.map(tokenize, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHDFWKnF3AyP"
      },
      "source": [
        "## Training (don't run during tutorial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hcKYiGWzeF5"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=dataset[\"train\"].features[\"label\"].num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjdVv-jMI2K3"
      },
      "outputs": [],
      "source": [
        "# optional if you want to save your models to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXlq8R9I0HqJ"
      },
      "outputs": [],
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/ds_conference/BERT-sentiment/\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=250,\n",
        "    save_total_limit=1,\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.0001,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHsMY8ynJRyL"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    pred = np.argmax(eval_pred.predictions, axis=-1)\n",
        "    accuracy = np.mean(pred == eval_pred.label_ids)\n",
        "    \n",
        "    return {\"accuracy\": accuracy}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BIRV3ZhJMDN"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tok_dataset[\"train\"],\n",
        "    eval_dataset=tok_dataset[\"val\"],\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbEe_kkZJ61w"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMXKbP1CRgxc"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJuGdGqGSoKc"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/bert-imdb\n",
        "!gdown -O /content/bert-imdb/config.json https://drive.google.com/uc?id=1-XtrUCTwyBnG79LpOYe6nfFeREg9hvfm\n",
        "!gdown -O /content/bert-imdb/pytorch_model.bin https://drive.google.com/uc?id=1-UnnVyANUEBULAhSBkZ9_fKKCXugV751"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xb7Es1vdRir1"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-imdb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "FsqtHYlPTvAK"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    pred = np.argmax(eval_pred.predictions, axis=-1)\n",
        "    accuracy = np.mean(pred == eval_pred.label_ids)\n",
        "    \n",
        "    return {\"accuracy\": accuracy}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6575pcXPT3DM"
      },
      "outputs": [],
      "source": [
        "args = TrainingArguments(\"test\", per_device_eval_batch_size=64)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    eval_dataset=tok_dataset[\"test\"].shuffle(42).select(range(2000)),  # for tutorial purposes, we subsample the test data\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USY6H-z2T6DJ"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToUM9uDyU-A6"
      },
      "source": [
        "## A bit more testing:)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CNDMM4uUXpJA"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoConfig, pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a091YkRGXWfz"
      },
      "outputs": [],
      "source": [
        "# just adds id2label to model config\n",
        "config = AutoConfig.from_pretrained(\"bert-imdb\")\n",
        "config.id2label = {\"0\": \"Negative\", \"1\": \"Positive\"}\n",
        "config.save_pretrained(\"bert-imdb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3a1wvFJVFOT"
      },
      "outputs": [],
      "source": [
        "classifier = pipeline(\"sentiment-analysis\", model=\"bert-imdb\", tokenizer=\"distilbert-base-uncased\", device=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iU6odTyVk4x"
      },
      "outputs": [],
      "source": [
        "classifier(\"This movie sucks!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_h1rwcNVVp1H"
      },
      "outputs": [],
      "source": [
        "classifier(\"This movie is great!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnX96jJ1WreV"
      },
      "outputs": [],
      "source": [
        "classifier(\"I don't think this movie is good.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "67a4cf080271e88ffe4802576fb974e913149b946dffd6a214c02f780aedddf8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
